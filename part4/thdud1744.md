# Part 4 처리율 제한 장치의 설계

rate limiter: 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한
장치. 특정 기간 내의 클라이언트 요청 횟수 제한. 임계치(threshold)넘어서면 추가로
도달한 호출은 처리 중단.

처리율 제한 장치를 두면 좋은 점:

1. DoS 공격에 의한 자원 고갈 방지
2. 비용 절감. 우선순위가 높은 API에 더 많은 자원 할당 가능.
3. 서버 과부하 방지.

## 1. 문제 이해 및 설계 범위 확정

면접관과 소통하며 어떤 제한 장치를 구현해야 하는지 구체화한다.

1. 어떤 종류의 처리율 제한 장치 필요? 서버 측? 클라이언트 측? -> e.g. 서버 측 
2. 어떤 기준을 사용해서 제어하는가? IP주소? 사용자 ID? -> e.g. 다양한 형태의
   제어 규칙(throttling role)을 가진 유연한 시스템
3. 시스템 규모는 어느 정도인가? 분산 환경에서 동작 가능한가? -> e.g. 대규모 요청
   처리 가능한 분산 시스템.
4. 독립된 서비스인가 애플리케이션 코드에 포함되는가? -> e.g. 본인 결정
5. 사용자의 요청이 걸러진 경우 notify? -> e.g. yes!

### 요구사항

- 설정된 처리율 초과하는 요청은 정확하게 제한한다
- 낮은 응답시간. 처리율 제한 장치가 시간을 지체하면 곤란
- 가능한 한 적은 메모리 사용
- 분산형 처리율 제한(distributed rate limiting): 하나의 처리율 제한 장치를 여러
  서버나 프로세스에서 ㄱㅇ유할 수 있어야 한다.
- 예외 처리: 요청이 제한되었을 때는 그 사실을 유저에게 알려야한다
- 높은 결함 감내성(fault tolerance): 제한 장치에 장애가 생겨도 시스템에 영향을
  주면 안됨.

## 2. 개략적 설계안 제시 및 동의 구하기

### 처리율 제한 장치는 어디에 둘 것인가?

- 클라이언트 측: 안정적이지 못함. 위변조 쉽다.
- 서버 측:
- 미들웨어:

HTTP 429: too many requests

클라우드 마이크로서비스의 경우 처리율 제한 장치는 보통 API 게이트웨이에 미들웨어
형식으로 구현. API 게이트웨이는 다음을 지원하는 완전 위탁관리형 서비스이다:

- 처리율 제한
- SSL termination
- authentication
- IP whitelist

#### 처리율 제한 장치는 어디에 두어야 하나?

- 프로그래밍 언어가나 캐시가 서버 측 구현을 지원하기 충분할 정도로 효율이
  높은가?
- 사업에 맞는 처리율 제한 알고리즘을 찾아라. 서버측에서는 알고리즘 선택이 비교적
  자유로우나 제 3자가 제공하는 게이트웨이 사용시 선택지 제한
- 이미 마이크로서비스 기반이고 API게이트웨이가 이미 존재한다면 여기에 추가해야할
  수도
- 직접 구현이 힘들다면 상용 API게이트웨이를 쓰는 것도 바람직

### 처리율 제한 알고리즘

### Token Bucket 토큰 버킷

간단하고 보현적. 아마존과 스트라이프가 사용

Token은 지정된 용량을 갖는 컨데이너. 토큰 공급기(refiller)로부터 주기적으로 사전
설정된 양의 토큰이 채워진다. 꽉찬 버킷에는 더이상 추가 노노. 공급된 추가 토큰은
버려진다.(overflow) 각 요청은 처리될 때마다 1개 토큰 사용. 요청이 도착하면
버킷에 충분한 토큰이 있는지 검사하고, 충분한 토큰이 있으면 토큰 하나를 꺼낸 후
요청 전달. 토큰 없으면 요청 버림(drop)
![4-5](/part4/images/4-5.png)

토큰 버킷의 크기가 4이고 토큰 공급률(refill rate)이 분당 4 일때의 예시:
![4-6](/part4/images/4-6.png)

알고리즘은 2개의 parameters 필요:

1. 버킷 크기:
2. 토큰 공급률: 초당 몇개의 토큰이 채워지는가

*버킷은 몇개를 사용해야 하는가?*

- 통상적인 경우: API endpoint마다 별도의 버킷. 사용자마다 하루 한 번 포스팅,
  좋아요 5개 이런 식으로 구성하면 사용자마다 버킷을 2개씩 두어야 한다.
- IP 주소별로 처율 제한한다면 IP 주소 1개마다 버킷 1개
- 시스템 처리율을 초당 10,000개로 제한하고싶으면 모든 요청이 하나의 버킷 공유

**장점**:

1. 구현이 쉽다
2. 메모리 사용 효율적
3. 짧은 시간에 집중되는 트래픽(burst of traffic)도 처리 가능

**단점**:

1. 버킷 크기와 토큰 공급률 이 두 개의 인자를 적절하게 튜닝하는 것은 까다롭다.

### Leaky Bucket 누출 버킷

쇼피파이가 사용.
앞선 토큰 버킷과 비슷하지만 요청 처리율이 고정되어 있다. 보통 FIFO큐로 구현한다.

- 요청이 도착하면 큐가 가득 찼는지 확인. 빈자리 있으면 큐에 요청 추가
- 가득찼으면 새 요청 버림.
- 지정된 시간마다 큐에서 요청 꺼내 처리
![4-7](/part4/images/4-7.png)

알고리즘은 2개의 parameters 필요:

1. 버킷 크기: 큐 사이즈와 같다.(큐에는 처리 할 항목 보관)
2. 처리율(outflow rate): 지정된 시간당 몇개의 항목을 처리할지.(초)

**장점**:

1. 큐 크기 제한으로 메모리 사용량 측면에서 효율적
2. 고정 치리율 가지고 있어 안정적 출력이(stable outflow rate) 필요한 경우 적합.

**단점**:

1. 단시간에 많은 트래픽이 몰리는 경우 큐에 오래된 요청이 쌓이고, 이게 제때
   처리되지 않으면 최신 요청들이 버려짐.
2. 버킷 크키(큐 크기)와 처리율을 올바르게 튜닝하기 까다롭다.

### Fixed Window Counter 고정 윈도 카운터

- 타임라인을 고정된 간격의 윈도로 나누고, 각 윈도마다 카운터가 붙는다,
- 요청이 접수될 때마다 카운터++;
- 카운터 값이 사전 설정 임계치(threshold)에 도달하면 새로운 요청은 새 윈도 열릴
  때까지 버려짐.

예시: 윈도우 크기 1초, 초당 3개까지 허용.
![4-8](/part4/images/4-8.png)

**문제**: 윈도 경계 부근에 순간적으로 많은 트래픽이 집중될 경우 윈도 할당량보다
더 많은 요청이 처리될 수 있음.

예시: 분당 5개 요청 허용:

- 2:00:00 - 2:01:00
- 2:01:00 - 2:02:00
- 2:00:30 - 2:01:30: 허용 한도의 2배 처리
![4-9](/part4/images/4-9.png)

**장점**:

1. 메모리 효율 좋다
2. 이해하기 쉽다,
3. 윈도 닫히는 시점에 카운터 초기화하면 특정 트래픽 패턴을 처리하기 적합.

**단점**:

1. 윈도 경계 부근에 일시적으로 많은 트래픽이 몰리는 경우, 기대했던 한도보다 많은
   양을 처리하게 됨.

### Sliding Window Log 이동 윈도 로그

이동 윈도 로깅 알고리즘은 앞선 알고리즘의 문제를 해결한다.

- 요청 timestamp 추적. 이 데이터는 보통 redis의 sorted set 같은 캐시에 보관.
- 새 요청이 오면 만료된 timestamp 제거. (현재 윈도 시작시점보다 오래된 것)
- 새 요청의 timestamp를 log 에 추가.
- 로크 크기가 허용치 범위 내에 있으면 요청 전달. 아니면 처리 거부

예시: 분당 2개 처리:

1. 요청 도착 시 로그는 비어있어서 허용됨.
2. 새로운 요청이 1:00:30 도착. 로그에 추가됨. 한도 범위 내라서 요청 허용.
3. 새로운 요청 1:00:50 도착. 한도 범위 넘어서 로그에는 남는데 허용은 노노.
4. 새 요청 1:01:40 도착. [1:00:40, 1:01:40) 이전의 타임스탬프는 만료되어 삭제.
   삭제 직후 로그 크기는 2로 범위 내이므로 요청 허용.
![4-10](/part4/images/4-10.png)

**장점**:

1. 아주 정교함. 어느 순간의 윈도를 보더라도 허용되는 요청 개수가 threshold 넘지
   않음.

**단점**:

1. 거부된 요청 timestamp도 보관하므로 다량의 메모리 사용.

### Sliding Window Counter 이동 윈도 카운터

고정 윈도 **카운터** + **이동 윈도** 로깅. 두가지 구현 방식 있으나 한 개만 설명.

예시: 분당 처리율 7. 직전 1분에 5개, 현재 1분에 3개가 도착.
현재 1분의 30% 시점에 도착한 새 요청의 경우, 처리해야 할까???
![4-11](/part4/images/4-11.png)

- 현재 윈도의 요청 개수 = 현재 1분간의 요청 수 + 직전 1분간의 요청 수 * 이동 윈도와 직전 1분이 겹치는
  비율

=> 현재 윈도에 들어있는 요청은 3+ 5*70% = 6.5 반올림이나 내림하여 쓸 수 있는데
예시에서는 내림하여 사용. 따라서 6개이다.

따라서 현재 1분의 30%시점에 도착한 신규 요청은 시스템에 전달되고, 그 이후 도착한
요청들은 한도에 도달했기 때문에 버려짐.

**장점**:

1. 이전 시간대의 평균 처리율에 따라 현재 윈도 상태를 계산하므로 짧은 시간에
   몰리는 트래픽에도 잘 대응
2. 메모리 효율 좋다.

**단점**:

1. 직전 시간대에 도착한 요청이 균등하게 분포되어있다고 가정한 상태에서 추정치를
   계산한거라 다소 느슨. 하지만 Cloudflare가 한 실험에 따르면 40억개 요청중에
   버려진 요청은 0.003%에 불과.

### 개략적인 아키텍쳐

요약:

- 얼마나 많은 요청이 접수되었는지 추적 가능한 카운터를 추적 대상(사용자,
IP주소, endpoint, 서비스 단위)별로 두고, 한도 넘어서면 요청 거부.
- 카운터는 어디에 보관할 것인가? 데이터베이스는 노노. 메모리상에서 동작하는
  캐시가 바람직. 빠르고 만료 정책 지원. Redis는 처리율제한장치 구현할 때 자주
  사용되는 메모리 기반 저장장치이다. INCR(카운터 증가), EXPIRE(카운터 타임아웃
  지나면 자동 삭제) 지원.

예시:

- 클라이언트가 처리율제한 미들웨어에게 요청 보냄.
- 처리율제한 미들웨어가 레디스 지정버킷에서 카운터 한도 도달 체크.
- 한도 도달시 요청 거부
- 한도 범위 내라면 요청 API서버로 전달하고 미들웨어는 레디스 카운터 증가.
![4-12](/part4/images/4-12.png)

## 3. 상세 설계

- 처리율 제한 규칙은 어떻게 만들어지고 어디에 저장되는가?
- 처리가 제한된 요청들은 어떻게 처리되는가?

### 처리율 제한 규칙

처리율 제한 규칙들은 보통 Config file로 디스크에 저장된다.
예시. Lyft는 처리율 제한에 오픈 소스 사용.
![marketing_limit](/part4/images/marketing_limit.png)
![login_limit](/part4/images/login_limit.png)

### 처리율 한도 초과 트래픽 처리

요청이 처리율제한에 걸리면 429 too many requests 보냄. 경우에 따라 나중에
처리하기 위헤 큐에 보관할수도, 아닐수도.

#### 처리율 제한 장치가 사용하는 HTTP헤더

클라이언트는 자기 요청이 처리율 제한에 걸리고 있는지 어떻게 감지하는가?
자기 요청이 처리율 제한에 걸리기까지 얼마나 많은 요청을 보낼 수 있는지 어떻게
아는가?

HTTP Response Header:

- X-Ratelimit-Remaining: 윈도 내에 남은 처리 가능 요청 수
- X-Ratelimit-Limit: 윈도마다 클라이언트가 전송할 수 있느 요청 수
- X-Ratelimit-Retry-After: 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시
  보내야 하는지.

### 상세 설계

- 처리율 제한 규칙은 디스크에 보관한다. 작업 프로세스는 수시로 규칙을 디스크에서
  읽어 캐시에 저장한다.
- 클라이언트가 요청을 서버에 보내면 먼저 처리율제한 미틀웨어에 도달
- 처리율제한미들웨어는 제한 규칙을 캐시에서 읽어온다. 또한 레디스 캐시에서
  카운터 및 마지막 요청 타임스탬프를 가져와 다음과 같은 결정을 내림
  - 해당 요청 통과! -> API로 전달
  - 처리율제한 걸림. 429, 요청 버리거나 메세지 큐 보관.
![4-13](/part4/images/4-13.png)

### 분산 환경에서의 처리율 제한 장치 구현

#### 경쟁 조건

두 개 요청을 처리하는 스레드가 각각 카운터 값을 읽고 아직 변경 값을 저장하지
않은 상태이다. 사실상 카운터 값은 5가 되어야 한다.
![4-14](/part4/images/4-14.png)

경쟁 문제를 해결하는 가장 널리 알려진 해결책은 Lock. 그러나 시스템 성능을 상당히
떨어뜨린다.

- Lua script
- Sorted Set(Redis)

#### 동기화 이슈

수백만 사용자를 지원하려면 처리율제한장치 서버 여러 대 필요. -> 동기화 필요성.

예시. 웹 계층은 무상태이기 때문에 동기화가 없을 시 처리율제한장치1은 클라이언트
2에 대해 정보가 없으므로 처리율 제한 불가.
![4-15](/part4/images/4-15.png)

고정 세선(Sticky session)을 활용할 수 있지만 확장성 없고 유연하지도 않기 때문에
비추. 레디스와 같은 중앙 집중형 데이터 저장소를 쓰는 것이 더 나은 해결책.
![4-16](/part4/images/4-16.png)

#### 성능 최적화

1. 여러 데이터센터 지원하는 것. 지연시간(latency) 유의. 가장 가까운 서버로
   전달하여 지연시간 줄이기.
2. 제한장치간 데이터 동기화 할 때 최종일관성모델(eventual consistency model)
   사용. -> 6장 키 값 저장소 설계 참고

#### 모니터링

모니터링을 통해 다음을 확인해야 함.

- 현재 처리율제한 알고리즘이 효과적인가?
- 정의된 처리율 제한 규칙이 효과적인가?

너무 빡빡하다면 많은 요청들이 버려짐 -> 규칙 다소 완화.

깜짝 세일 같은 트래픽 급증시 처리율제한장치가 비효율적이라면 알고리즘 바꾸는 것
고려. e.g. token bucket

## 4. 마무리

- 경성 또는 연성 처리율 제한
  - 경성(hard): 요청의 개수는 절대 임계치를 넘을 수 없다.
  - 연성(soft): 요청 개수는 잠시동안은 임계치 넘어도 된다.
- 다양한 계층에서의 처리율 제한.
  - 1. 물리 계층
  - 2. 데이터 링크 계층
  - 3. 네트워크 계층 // Iptables 사용 시 IP주소에 처리율 제한 적용
  - 4. 전송 계층(transport)
  - 5. 세션 계층
  - 6. 표현 계층(presentation)
  - 7. 어플리케이션 계층 // 이번 장에서 살펴본 것.
- 처리율 제한 자체를 회피하는 법. 어떻게 클라이언트를 설계할 것인가?
  - 클라이언트 측 캐시 할용.
  - 처리율 제한 임계치를 이해하고 짧은 시간동안 많은 메시지 보내지 않도록
  - 예외, 에러 처리. 클라이언트가 gracefully 복구 가능하도록
  - retry logic 구현시 충분한 back-off시간 설정
