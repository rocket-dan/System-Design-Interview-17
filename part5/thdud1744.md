# Part 5 안정 해시 설계

안정 해시는 수평적 규모 확장성을 달성하기 위해 요청(데이터)를 서버에 균등하게
나누는 목표를 달성하기 위한 기술이다.

## 해시 키 재배치(Rehash) 문제

N개의 캐시 서버가 있을 때 부하를 균등하게 나누는 보편적 방법

serverIndex = hash(key) % N

다음은 서버가 4 대 (N = 4)일 때의 예시이다.
![table-5-1](/part5/images/table-5-1.png)
![5-1](/part5/images/5-1.png)

이 방법은 *Server Pool의 크기가 고정되어 있을 때*나 *데이터 분포가 균등할 때* 잘
작동한다. 하지만 서버가 추가되거나 기존 서버가 삭제되면 문제가 생긴다.

예를들어 1번 서버가 장애를 일으켜 멈추었을 때 서버 풀의 크기는 3으로 변한다. 
![table-5-2](/part5/images/table-5-2.png)
![5-2](/part5/images/5-2.png)

1번 서버에 보관되어있는 키 뿐만 아니라 대부분의 키가 재분배되었다. 1번 서버가
죽으면 대부분 캐시 클라이언트가 데이터가 없는 엉뚱한 서버에 접속하게 된다.(Cache
Miss)

## 안정 해시

안정 해시는 위에 언급한 Cache Miss를 효과적으로 해결하는 기술이다. 해시 테이블
크기가 조정될 때 평균적으로 **K(키의 개수) / N(슬롯의 개수)개**의 키만
재배치하는 해시 기술이다. (대부분의 전통적 해시 테이블은 슬롯 수가 바뀌면
대부분의 키를 재배치한다.)

## 해시 공간과 해시 링

해시 함수 f는 SHA-1을 사용하고, 함수의 출력 값 범위는 x0, x1, ... xn과 같다.
SHA-1의 해시 공간(Hash Space) 범위는 0 부터 2^160 -1 까지라고 알려져 있다.
따라서 x0은 0이고, xn은 2^160 -1이다.
![5-3](/part5/images/5-3.png)
이 공간의 양쪽을 구부려 접으면 hash ring이 만들어진다.
![5-4](/part5/images/5-4.png)

## 해시 서버

이 해시 함수 f를 사용하면 서버 IP나 이름을 이 링 위의 어떤 위치에 대응시킬 수
있다.

다음은 4개의 서버를 해시 링 위에 배치한 결과이다.
![5-5](/part5/images/5-5.png)

## 해시 키

캐시할 키 key0, key1, key2, key3또한 해시 링 위의 어느 지점에 배치할 수 있다.
![5-6](/part5/images/5-6.png)

## 서버 조회

어떤 키가 저장되는 서버는 해당 키의 위치로부터 시계 방향으로 링을 탐색해나가면서
만나는 첫 번째 서버다.
![5-7](/part5/images/5-7.png)

## 서버 추가

위에 따른 서버 배치는 서버를 추가하더라도 키 가운데 일부만 재배치하면 된다.
새로운 서버 4가 추가될 경우 key0만 재배치되었다. key0이 시계방향으로 순회해
처음으로 만나는 서버가 서버4 이다.
![5-8](/part5/images/5-8.png)

## 서버 제거

하나의 서버가 제거되면 키 가운데 일부만 재배치된다.
서버1이 삭제되었을때 key1만 서버2로 재배치되었다.
![5-9](/part5/images/5-9.png)

## 기본 구현법의 두 가지 문제

안정해시 알고리즘은 MIT에서 처음 제안되었다.

* 서버와 키를 균둥 분포(uniform distribution) 해시 함수를 사용해 해시 링에
  배치한다.

* 키의 위치에서 링을 시계 방향으로 탐색하다가 만나는 최초의 서버가 키가 저장될
  서버다.

이 접근법애는 두 가지 문제가 있다.

1. 서버가 추가되거나 삭제되는 상황을 감안하면 파티션의 크기를 균등하게 유지하는
   게 불가능하다. (파티션은 인접한 서버 사이의 해시 공간)
   다음 그림은 서버1이 삭제되면서 서버2의 파티션이 매우 커지는 것을 볼 수 있다.
![5-10](/part5/images/5-10.png)

2. 키의 균등 분포를 달성하기가 어렵다. 서버1과 서버3이 아무 데이터도 갖지 않는 반면 서버2가 대부분의 키를 보관한다.
![5-11](/part5/images/5-11.png)
이 문제를 해결하기 위한 것이 Virtual Node(가상노드) 또는 Replica(복제)라고
불리는 기법이다.

## Virtual Node 가상 노드

가상노드는 실제 노드 또는 서버를 가리키는 노드로, 하나의 서버는 링 위에 여러
개의 가상 노드를 가질 수 있다.
이 그림에서 서버0과 서버1은 3개의 가상 노드를 갖는다.(실제 시스템에서는 그보다
훨씬 큰 값이 사용된다.) 따라서 각 서버는 하나가 아닌 여러 개 파티션을 관리해야
한다.
![5-12](/part5/images/5-12.png)

키의 위치로부터 시계방향으로 링을 탐색하다 만나는 최초의 가상 노드가 해당 키가
저장될 서버가 된다.
![5-13](/part5/images/5-13.png)
가상 노드의 개수를 늘리면 키의 분포는 점점 더 균등해진다. 표준 편차(standard
deviation)가 작아져서 데이터가 고르게 분포되기 때문. 표준편차는 데이터가 어떻게
퍼져 나갔는지를 보이는 척도다. 가상 노드의 개수를 더 늘리면 표준 편차의 값은 더
떨어진다. 그러나 가상노트 데이터를 저장할 공간은 더 많이 필요할 것.
즉 타협적 결정(tradeoff)이 필요하다. 시스템 요구사항에 맞도록 적절히 조정해야
함.

## 재베치할 키 결정

서버가 추가/제거 될 때 어느 범위의 키들이 재배치되어야 할까?

서버 4가 추가되었을때, 이에 영향 받은 범위는 서버4부터 그 반시계 방향의
서버3까지이다. 즉 이범위에 있는 키들을 서버4로 재배치해야한다.
![5-14](/part5/images/5-14.png)

서버1이 삭제되었을때, 서버1부터 그 반시계방향의 서버0사이의 키들이 서버2로 재배치되어야한다.
![5-15](/part5/images/5-15.png)

## 마치며

안정 해시의 이점:

* 서버가 추가되거나 삭제될 때 재배치되는 키의 수가 최소화된다.

* 데이터가 보다 균등하게 분포하게 되므로 수평적 규모 확장성을 달성하기 쉽다.

* 핫스팟(hotspot) 키 문제를 줄인다. (특정 샤드에 대한 접근이 지나치게 빈번하면
  과부하 문제) 안정해시는 데이터를 좀 더 균등하게 분배하므로 이런 문제가 생길
  가능성 줄임.
  
유명한 안정 해시의 예시:

* Amazon DynamoDB 파티셔닝 관련 컴포넌트

* Apache Cassandra 클러스터에서 데이터 파티셔닝

* Discord 채팅 어플리케이션

* Akamai CDN

* Meglev 네트워크 부하 분산기
